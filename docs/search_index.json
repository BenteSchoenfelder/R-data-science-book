[
["index.html", "R Data Science Book 1 Introduction 1.1 Goals 1.2 Data 1.3 Git and GitHub", " R Data Science Book Tools and Programming Languages for Data Scientists, FH Kiel, Summer Term 2020 2020-04-21 1 Introduction 1.1 Goals This book is a joint effort of the course “Tools and Programming Languages for Data Science”, FH Kiel. We develop this book, in order to learn how typical data wrangling tasks can be solved using the programming language R and in order to practice collaborative programming workflows using Git and GitHub. All of the R packages that we are going to cover are already extensively documented in books, online, and R help files. Our mission for this book is to investigate what these packages are good for, think about good example use cases in the context of data that we know, and apply their functionalities to these data. We start with core tidyverse packages that facilitate the data science workflow: tidying the data using the tidyr package, and exploring the data using the dplyr package. We work on tidyverse packages dedicated for specific data types: stringr for text data, lubridate for dates and times, and forcats for categorical variables. If data sets are huge we may run into performance problems. Hence, we explore the advantages of the data.table package for high performance computing in R. 1.2 Data The whole book is supposed to be based on the data contained in the data subdirectory. Please ask me if you would like to add another data set (e.g. because it would allow you to better demonstrate the functionalities of your package). Currently, the following data sets are covered: diamonds: data on diamonds; 50000 rows; categorical and numeric variables spotify-charts-germany: German daily top 200 charts for one year; 70000 rows; mostly numeric variables and dates olympic-games: data on olympic games medallists; 250000 rows, categorical and numeric data recipes: data on recipes; 60000 rows; character, date, and numeric variables related information weather-kiel-holtenau: weather data for Kiel-Holtenau in 10-Minute intervals for one year, 50000 rows; Date, time and numeric variables. 1.3 Git and GitHub We will work in teams of 2 students per topic. An important part of the book project is practicing collaborative workflows using Git and Github. We will use the Forking Workflow which is typical of open source projects. This involves the following steps: Fork the ‘official’ GitHub repository (“upstream”). This creates your own GitHub copy (“origin”). Clone your fork to your local system. Connect your local clone to the upstream repo by adding a remote path. Create a new local feature branch. Make changes on the new branch and create commits for these changes. Push the branch to your GitHub repo (“origin”) Open a pull request on GitHub to the upstream repository. Your team mate reviews your pull request. Once approved, it is merged into the upstream repo. How to connect your local clone to the upstream repo? # Check the currently registered remote repositories git remote -v # Add the upstream repo git remote add upstream https://github.com/tillschwoerer/R-data-science-book.git How can I integrate changes in the upstream repo into my local system? Best practice is to regularly pull upstream changes into the master branch of your local system, and then create a new feature branch, in which you make your own edits and commits. Never edit the master yourself. If you follow this routine, the pull won’t cause any conflicts - it will be a so called fast forward merge. To be on the save side use git pull upstream master --ff-only. The --ff-only flag means that the upstream changes are merged into the master only if it is a fast forward merge. If you have accidently made commits to the master, you will get an error message. In this case follow the steps described here to resolve the conflict. Further literature: https://happygitwithr.com/fork-and-clone.html https://www.atlassian.com/git/tutorials/comparing-workflows/forking-workflow "],
["tidyr.html", "2 Tidying data: tidyr", " 2 Tidying data: tidyr "],
["dplyr.html", "3 Wrangling data: dplyr", " 3 Wrangling data: dplyr library(tidyverse) df &lt;- read_csv(&quot;data/diamonds.csv&quot;) ## Parsed with column specification: ## cols( ## carat = col_double(), ## cut = col_character(), ## color = col_character(), ## clarity = col_character(), ## depth = col_double(), ## table = col_double(), ## price = col_double(), ## x = col_double(), ## y = col_double(), ## z = col_double() ## ) df %&gt;% names() ## [1] &quot;carat&quot; &quot;cut&quot; &quot;color&quot; &quot;clarity&quot; &quot;depth&quot; &quot;table&quot; &quot;price&quot; ## [8] &quot;x&quot; &quot;y&quot; &quot;z&quot; df %&gt;% group_by(color) %&gt;% summarise(MEANPRICE = mean(price)) "],
["lubridate.html", "4 Dates and times: lubridate 4.1 Background 4.2 Basics 4.3 Application - Import, Clean Data / date-time 4.4 Application - Create new date-time Variables 4.5 Application - Exploration - Analysis 4.6 Application - Visualisation of core findings 4.7 Wrap up - outlook date-time / time-series 4.8 Wrap up - What’s next/out there?", " 4 Dates and times: lubridate Resources: Lubridate homepage Cheatsheet Book Chapter in R4DS Vignette Suggested data set: weather-kiel-holtenau 4.1 Background 4.1.1 What is Lubridate? Lubridate is an R-Package designed to ease working with date/time variables. These can be quite challenging in baseR and lubridate makes working with dates and times more frictionless, hence the name. How to install package and what are usefull other libraries? Part of tidyverse? In short - what is tidyverse package.install(“lubridate”) package.install(“tidyverse”) package.install(“time-series”) 4.2 Basics Some examples of real world time formats found in datasets: Three types of date/time data Sys.time() functions Time Formats 4.3 Application - Import, Clean Data / date-time Weather data from on stationary sensor in Kiel-Holtenau. Import the data with readr - create a tibble (Idea - check, if data is openly available as well. This could lead to an excurse about how to generate a raw dataset from this weatherstation.) Examine the data - - summarise, glimpse an other exploration functions Parse the date-time Variable into a productive format The result should be a tidy data frame. Create an overview over the units of measured variables. possible: Formats and representation of the data. European vs. US number formats etc. possible: check time-series package, if this would help us in any way to make data even more accessible? 4.4 Application - Create new date-time Variables week of year (mutate) separate daytime vs. nighttime separate seasons (spring, summer, fall, winter) 4.5 Application - Exploration - Analysis Calculate Average Temperatures (d/m/season/y) Calculate Averages for humdity, rainfall etc. Plus many more insights, that are not apparent at this draft stage. 4.6 Application - Visualisation of core findings How has the climate changed during the observed intervall? How can relevant intervalls be compared? can we find historic KPIs to compare our findings (eg. average temperature in January in Kiel 1900) What Visualisations make sense for our kind of data/insights? Research and try&amp;error 4.7 Wrap up - outlook date-time / time-series what potential problems have not been adressed? 4.8 Wrap up - What’s next/out there? Insights from data / data vis What potential problems have not been adressed? (Time series package? etc?) "],
["forcats.html", "5 Categorical data: forcats 5.1 Introduction 5.2 General functions 5.3 Combine factors 5.4 Order of levels 5.5 Value of levels 5.6 Add or drop levels", " 5 Categorical data: forcats 5.1 Introduction This chapter is dedicated to the handling of categorical variables. This becomes important if information is to be presented in a non-alphabetical order or aggregated in a meaningful way. Within the R programming language, categorical variables are converted into a form that can be used for analysis using factors. While many Base-R functions automatically convert character vectors into factors, tidyverse requires an explicit treatment. The core-tidyverse provides the package forcats, which will be described here. Further information and exercises are available at the sources shown. Resources: Homepage Cheatsheet Chapter in R4DS Vignette In this chapter the demo data set “diamonds” from the ggplot2-package (more information) and a dataset “olympic-games” which shows the medal success of olympic athletes from 1896 to 2016 are used. Before you start reading, you should have read the chapter Wrangling Data: dplyr or already have basic knowledge in this field. library(tidyverse) diamonds &lt;- read_csv(&quot;data/diamonds.csv&quot;) olympic &lt;- read_csv(&quot;data/olympic-games.csv&quot;) head(diamonds) head(olympic) 5.2 General functions 5.2.1 Create Basically two things are needed to create a factor. A vector which contains the values to be analyzed and a vector which divides the values into levels. As an example we will use the column “clarity” of the diamonds dataset. It is a categorical evaluation of the clarity of a diamond (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best)). If you are interested in the distribution of the diamonds in this category, you could do this by using a suitable query: diamonds %&gt;% group_by(clarity) %&gt;% count() %&gt;% ggplot(aes(clarity, n)) + geom_col() A sorting of the x-axis, which is based on the degree of clarity, is unfortunately not possible in this form. A workaround is to convert this column into a factor, which allows us to evaluate the individual categories. For this purpose we first define a vector, which ranks the categories according to their value: levels_clarity &lt;- c(&quot;I1&quot;, &quot;SI2&quot;, &quot;SI1&quot;, &quot;VS2&quot;, &quot;VS1&quot;, &quot;VVS2&quot;, &quot;VVS1&quot;, &quot;IF&quot;) In the next step we lay this newly created levels vector on the column “clarity” of our data set to create a factor. factor() is a base-R function. factor_clarity &lt;- factor(x = diamonds$clarity, levels = levels_clarity) Another possibility to create a factor is to convert a vector using as_factor().. Here the levels are created automatically. Their order depends on the appearance of the corresponding value in the source vector. as_factor(diamonds$clarity) %&gt;% levels() ## [1] &quot;SI2&quot; &quot;SI1&quot; &quot;VS1&quot; &quot;VS2&quot; &quot;VVS2&quot; &quot;VVS1&quot; &quot;I1&quot; &quot;IF&quot; 5.2.2 Count values per level Now we repeat the analysis of the distribution within our dataset using the created factor. The function fct_count() returns the frequency of a categorical value within a factor. The order of the levels remains unchanged. fct_count(factor_clarity) %&gt;% ggplot(aes(clarity, n)) + #the definition of aes. mapping in this line is only used to label the axes geom_col(aes(f, n)) It becomes obvious that the distribution can now be displayed in the desired order (by valence). Functions of the package forcats always start with the prefix fct_. 5.2.3 Inspect and set levels With the function levels() the levels of a factor can be both read and defined. But be aware : this can only be used to change the names, not the order of the levels. The base-R function unclass() gives information about the internal memory structure of a factor. factor_clarity %&gt;% levels() #shows the original levels of our factor ## [1] &quot;I1&quot; &quot;SI2&quot; &quot;SI1&quot; &quot;VS2&quot; &quot;VS1&quot; &quot;VVS2&quot; &quot;VVS1&quot; &quot;IF&quot; factor_clarity[1:25] %&gt;% unclass() #shows the internal structure ## [1] 2 3 5 4 2 6 7 3 4 5 3 5 3 2 2 1 2 3 3 3 2 4 5 3 3 ## attr(,&quot;levels&quot;) ## [1] &quot;I1&quot; &quot;SI2&quot; &quot;SI1&quot; &quot;VS2&quot; &quot;VS1&quot; &quot;VVS2&quot; &quot;VVS1&quot; &quot;IF&quot; #remain the semantic order but replace the technical jargon with something understandable levels(factor_clarity) &lt;- c(&quot;c8&quot;, &quot;c7&quot;, &quot;c6&quot;, &quot;c5&quot;, &quot;c4&quot;, &quot;c3&quot;, &quot;c2&quot;, &quot;c1&quot;) factor_clarity %&gt;% head(25) ## [1] c7 c6 c4 c5 c7 c3 c2 c6 c5 c4 c6 c4 c6 c7 c7 c8 c7 c6 c6 c6 c7 c5 c4 c6 c6 ## Levels: c8 c7 c6 c5 c4 c3 c2 c1 5.2.4 Inspect unique values The function fct_unique can be used to output unique values of a factor. In contrast to the base-R function unique() the values are returned in the order of the levels and not in the order of their appearance. factor_clarity %&gt;% fct_unique() ## [1] c8 c7 c6 c5 c4 c3 c2 c1 ## Levels: c8 c7 c6 c5 c4 c3 c2 c1 factor_clarity %&gt;% unique() ## [1] c7 c6 c4 c5 c3 c2 c8 c1 ## Levels: c8 c7 c6 c5 c4 c3 c2 c1 5.3 Combine factors 5.4 Order of levels 5.5 Value of levels 5.6 Add or drop levels "],
["stringr.html", "6 Character data: stringr", " 6 Character data: stringr Resources: Homepage Book Chapter in R4DS Cheatsheet Vignette Into Vignette Regular Expressions Suggested data: recipes Advice: Many of the examples in the Vignettes just refer to vectors. How can we use stringr to create/modify character columns of a data frame? "],
["data-table.html", "7 High performance computing: data.table", " 7 High performance computing: data.table Resources: Vignette Intro Vignette on reference semantics Github Wiki Cheatsheet data.table vs. dplyr Suggested data: any Possible approach: take different sequences of operations in dplyr and translate it into data.table syntax. Then summarise differences and pros/cons vis-à-vis dplyr "]
]
