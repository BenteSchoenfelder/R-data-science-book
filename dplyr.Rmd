# Wrangling data: dplyr {#dplyr}

The R package `dplry` is described as a grammar of data manipulation. It provides commands for the most frequently used types of data transformations, either for the purpose of exploration, data cleaning, or augmenting data.

The package is part of the core tidyverse, which means that we can load it either explictly via `library(dplyr)` or implictly via `library(tidyverse)`. Note that in the following, all commands that are not `dplyr` commands are made explicit via `<package>::<command>`. To demonstrate the main features, we use data on Spotify's daily top 200 charts in Germany in the course of one year. 

```{r load_data, message=FALSE, warning=FALSE}
library(tidyverse)     # alternatively use library(tidyverse) which covers dplyr + more
df <- readr::read_csv("data/spotify_charts_germany.csv")
```

## Two typial workflows
Before looking in detail into specific functions, let's start with two typical workflows. We will note that 

- dplyr works with the pipe (`%`) such that multiple operations can be combined one after the other, without the need to create intermediate results. 
- function names are quite expressive, basically telling us what they are doing.
- there is a strong analogy to SQL: due to this analogy it is even possible to run dplyr commands with a database backend (the package `dbplyr` needs to be installed)

The first workflow returns an ordered list of the 10 tracks with the highest number of streams on a single day, together with information on the number of streams, day, artist, and track name. 

```{r workflow1}
df %>%                                              # data
  arrange(-Streams) %>%                             # order rows by some variable 
  select(Streams, date, Artist, Track.Name) %>%     # select columns by name
  slice(1:10)                                       # select rows by position

```
The second workflow returns the average number of streams per day of week since the beginning of the year 2020. For this operation, the day of week is derived from the date and added as an additional variable via the `mutate` function. 

```{r workflow2}
df %>%                                 # data              
  filter(date>="2020-01-01") %>%       # select rows where condition evaluates to TRUE
                                       # create an additional variable 
  mutate(day_of_week=lubridate::wday(date, label=TRUE, abbr=FALSE, 
                                     locale="American_America.1252", week_start=1)) %>%
  group_by(day_of_week) %>%            # group the data 
  summarise(streams = mean(Streams))   # aggregate per group via functions such as mean, min, etc. 
        
```

Note that in this particular case, we can write the code more concise by generating the new variable `day_of_week` inside the `group_by` function.

```{r workflow2b, eval=FALSE}
df %>%                                              
  filter(date>="2020-01-01") %>%                    
  group_by(day_of_week=lubridate::wday(date, label=TRUE, abbr=FALSE, locale="American_America.1252", week_start=1)) %>% 
  summarise(streams = mean(Streams))          
```

## Manipulating rows
### Extract rows
The `filter` function is the most frequently used function to extract a subset of rows. The command extracts all rows where the filter condition(s) evaluate to TRUE. The `distinct` function returns distinct rows by removing duplicates (either for the whole data or the specified variables).

```{r filter}
df %>% 
  filter(stringr::str_detect(Track.Name, "Santa")) %>% # extract rows where condition is TRUE
  distinct(Artist, Track.Name)          # extract distinct combinations of the two variables
```

We can select rows by position via `slice`. Alternatively, we can use the functions `top_n` of `top_fraq` to extract a specified number or fraction of rows. Different from `slice` these functions operate also on grouped data, and we can specify according to which variables the top rows shall be chosen. 

```{r top_n}
df %>%                        
  group_by(date) %>%        # group by date 
  top_n(1, wt=Streams) %>%  # select 1 row per date, the one with the highest number of streams
  slice(1:10) %>%           # return only the first 10 rows of the resulting data frame
  select(date, Streams, Track.Name, Artist)
```

Another useful feature is selecting rows randomly via `sample_n` or `sample_frac`.
```{r sample_n}
df %>% sample_n(5, replace = TRUE) # Select 5 rows randomly with replacement
```
### Arranging rows
The function `arrange` is used to order rows by some variable(s). Use minus (`-`) or the `desc` function for arranging in descending order. The following code returns the five most danceable chart tracks of 2019-03-30 by arranging first by date (ascending) and second by danceability (descending). 
```{r arrange}
df %>% 
  arrange(date, -danceability) %>% 
  slice(1:5) %>% 
  select(Track.Name, date, danceability)
```

## Manipulating columns
### Extract and rename columns
Subset of columns can be extracted via the `select` function. Selection is possible by name or position. Reversely, one can exclude specific columns via negative selection (using `-`). Noteworthy are are the many  helper functions, which are convenient for rapid exploration, but not recommendable for stable software: `start_with`, `last_col`, `everything`, `contains`, etc. One can rename columns while selecting them. If we want to rename a column while preserving the other columns we use the `rename` function.
```{r select, eval=FALSE}
df %>% select(Position, Track.Name)       # select via column name
df %>% select(1, 2)                       # select via column position
df %>% select(-Track.Name)                # select all columns except Track.Name
df %>% select(starts_with("dance"))       # select all columns starting with "dance" 
df %>% select(danceability, everything()) # reorder danceability first, then remaining columns
df %>% select(song = Track.Name)          # select one column (Track.name) and rename it (song)
df %>% rename(song = Track.Name)          # renames one column, but preserves all the others 
```
### Create new columns
The function `mutate` creates a new variable or overwrites an existing one. Note that we must assign back to make a permanent change to the data. 

```{r mutate}
df %>% 
  mutate(duration_s = round(duration_ms / 1000)) %>%  # create new variable
  mutate(Track.Name = as.factor(Track.Name)) %>%      # change existing variable
  select(Track.Name,starts_with("duration")) %>%
  head(5)
```

## Scoped functions
There are scoped variants of ,`mutate` which affect multiple columns at once: 

- `mutate_all`: all columns
- `mutate_at`: all specified columns
- `mutate_if`: all columns that satisfy a condition 

Equivalent scoped variants exist for `select`and `summarise` as well.

```{r mutate_all}
df %>% mutate_all(as.character) %>% str()  # change ALL columns to character type
```

```{r mutate_at}
# Apply the function round to ALL SPECIFIED columns
df %>% 
  mutate_at(vars(danceability, valence), round, digits=1) %>% 
  select(Track.Name,danceability, valence)
  head(5)
```
If there is no predefined function, one can define an anonymous function (which cannot be used outside this context) on the fly:
```{r anonymous_function}
# transmute is a variant of mutate
df %>% 
  mutate_at(vars(danceability, valence), function(x) x*100) %>%
  select(Track.Name,danceability, valence)
  head(5)
```

The typical use case for `mutate_if` is changing the variable types of all variables satisfying a specific condition. 
```{r mutate_if}
df %>% 
  mutate_if(is.character, as.factor) %>%  # turns all character variables into factors
  glimpse()
```

Note that the condition above (`is.character`) refers to the column as a whole, i.e. the condition returns a single TRUE or FALSE. If we want to mutate a column conditional on the single elements within the column, we use the regular `mutate` function combined with an `if_else`:
```{r if_else}
df %>% 
  mutate(Top10 = if_else(Position<=10, "Top 10", "Top 11-200")) %>%
  select(Position, Top10, Track.Name) %>%
  slice(8:12)
```


## Summarise
The `summarise` function is the generic way of calculating summary stats for specific variables. Within the function we can apply base R summary functions (`sum`, `mean` or `max`), one of dplyr's specific summary functions (`n`, `n_distinct`) or a user defined summary function. In the standard case the `summarise` function returns one row.
```{r summarise}
df %>% 
  filter(date == max(date)) %>%
  summarise(observations = n(),                       # number of observations (dplyr function)
            artists = n_distinct(Artist),             # number of distinct observations (dplyr)
            total_streams = sum(Streams),             # sum (base R) 
            mean_valence = mean(valence, na.rm=TRUE)) # mean (base R)
```

However, we can also apply `summarise` to grouped data. Then one row is returned per group.
```{r group_by}
df %>% 
  group_by(month = stringr::str_sub(date, 1, 7)) %>%
  summarise(artists = n_distinct(Artist),             # number of distinct observations (dplyr)
            total_streams = sum(Streams),             # sum (base R) 
            mean_valence = mean(valence, na.rm=TRUE)) # mean (base R)
```

The `count` function is a useful shortcut for `group_by` followed by `summarise(n = n())`.
```{r count}
df %>% count(Artist)
# df %>% group_by(Artist) %>% summarise(n = n()) %>% ungroup()
```

Sometimes, we want to add the (group) aggregates as a new column to the existing data frame. In this case we just use `mutate` rather than `summarise`. 
```{r mutate_aggregates}
df %>% 
  group_by(date) %>%
  mutate(Total_Streams = sum(Streams), Share = Streams/Total_Streams) %>%
  select(Streams, Total_Streams, Share, Artist)
```


## Combining tables
## Database backend
### Motivation
As mentioned before, the `dplyr` syntax reveals strong analogies with SQL. What is more, it is even possible to use `dplyr` with a database backend. 

**What does this mean? And when is this useful?**

In a company setting, raw data is usually stored in some form of database. When we want to work with the data in R, the standard way would be to open a connection to the database and read in the data into R's memory. However, if the size of data is large, there may be problems with this approach: 

- Large data require long reading time 
- Data sets might not even fit into memory
- Computations might have low performance

If we want to work on the raw data (e.g. for statistical / machine learning modelling), this constitutes a problem: either we need a system with larger memory / higher performance. Or we must restrict ourselves to a smaller sample of the data. Or we could connect R to a technology for distributed machine learning, such as Apache Spark.

In some cases, however, we don't actually need to work on the raw data. We would be happy to let the database do the calculations for us (these are built to store and process huge amounts of data), and just read in the resulting data, which is often much smaller in size. This is precisely the use case for dplyr with a database backend.

The idea is to write regular dplyr code. The code is translated into SQL under the hood. The data is retrieved from the database and only the results are actually read into R's memory. Since this data is often much smaller, this requires only litte time.

### Set up
First, we need to install a few things: 

- **Database:** In a company setting, the database will already be there. If you want to install a database on your computer, popular choices are PostgreSQL or MySQL. Here is an [overview of possible choices](https://db.rstudio.com/databases/)S For this book we will use an in-memory SQLite database. The benefit is that everyone will be able to run the code without the need to set up a proper database.    
- **DBI backend package:** DBI stands for database interface. We need a package that corresponds to our database. In our case we will use the package `RSQLite`. With many other databases, the package `odbc` would be proper choice.
- **`dbplyr` package** This package needs to be installed, but we never need to load it explictly. Once installed, it is sufficient to load the regular `dplyr` package.

Second, we need to connect R to the database. The arguments look slightly different, depending on the database that you are using. 
```{r db-connect}
con <- DBI::dbConnect(RSQLite::SQLite(), dbname = ":memory:")
```

Third, we need to have data in our database. In a company setting, the data would already be there. In our case, we are copying our data into a table called `spotify-charts-germany` of our SQLite in-memory database.
```{r}
copy_to(con, df, "spotify-charts-germany")
```

### Querying the database
A standard way of reading data into R from a database would be via an explicit SQL query:
```{r}
query <- "SELECT `Track.Name`, Artist, Streams FROM `spotify-charts-germany` LIMIT 5"
RSQLite::dbGetQuery(con, query)
```

But we want to do this differently: we are going to use `dplyr` syntax to query the database. For that we need to first register the database table via `tbl`. Now we can already preview the first rows of the table.

```{r paged.print = FALSE}
spotify_db <- tbl(con, "spotify-charts-germany")
spotify_db
```

We see that the following query uses standad dplyr syntax, although we are now creating an SQL query, to be run against a database. 
```{r}
query <- 
  spotify_db %>%                                    # data
  arrange(-Streams) %>%                             # order rows by some variable 
  select(Streams, date, Artist, Track.Name) %>%     # select columns by name
  head(5)                                           # select rows by position  
query
```

We can actually see the SQL generated in the background via `show_query`. 

```{r}
query %>% show_query()  # shows the translation into SQL
```

It is important to understand that the data is not in R's memory until we explicitly `collect` the data. Once the data is collected, it behaves like any regular R data frame.
```{r}
rdata <- query %>% collect()  # this pulls the data into R's memory
class(rdata)                  # this is a regular R data frame / tibble
class(query)                  # ... while query is a SQLite Connection object
```




